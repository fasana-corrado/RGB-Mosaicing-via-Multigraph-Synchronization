{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1af4778a-c650-445c-8464-5401488b2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import networkx as nx\n",
    "from IPython.display import Audio, display\n",
    "import ipynb.fs.defs.Utils as Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5365d9e3-37ec-440f-a955-b840c05a1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allDone():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/001/131/original/kon.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "17d78987-9a8a-4dbe-ab83-1566030debd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class contains the methods and properties related to the features of an image\n",
    "class ImageFeature:\n",
    "    def __init__(self, image, index):\n",
    "        self.image = image\n",
    "        self.index = index  \n",
    "        \n",
    "    #Compute the salient points of the image using SIFT algorithm\n",
    "    def SIFT(self, save_output = False, output_dir = \"output\"):\n",
    "        sift = cv.SIFT_create()\n",
    "        self.kp, self.des = sift.detectAndCompute(self.image,None)\n",
    "        self.img_with_sift=cv.drawKeypoints(self.image,self.kp,self.image)\n",
    "        if save_output:\n",
    "            cv.imwrite(os.path.join(output_dir,f\"{self.index+1}.jpg\"), self.img_with_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a9e1ce70-ef10-43c4-a83b-a6d8710f9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class contains the methods and properties related to the problem of feature matching between two images\n",
    "class Match:\n",
    "    def __init__(self, image_feature_source, image_feature_destination):\n",
    "        self.image_feature_source = image_feature_source\n",
    "        self.image_feature_destination = image_feature_destination\n",
    "    \n",
    "    #This function performs feature matching between to images\n",
    "    def feature_matching(self, threshold, save_output = False, output_dir = \"output\"):\n",
    "        # FLANN parameters\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "        flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "        matches = flann.knnMatch(self.image_feature_source.des,\n",
    "                                 self.image_feature_destination.des,\n",
    "                                 k=2)\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        self.good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < threshold*n.distance:\n",
    "                self.good.append((m,n))\n",
    "        draw_params = dict(matchColor = (0,255,0),\n",
    "                           singlePointColor = (255,0,0),\n",
    "                           flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "        self.img_with_match = cv.drawMatchesKnn(self.image_feature_source.image,\n",
    "                                                self.image_feature_source.kp,\n",
    "                                                self.image_feature_destination.image,\n",
    "                                                self.image_feature_destination.kp,\n",
    "                                                self.good,None,**draw_params)\n",
    "        if save_output:\n",
    "            cv.imwrite(os.path.join(output_dir,f\"match_{self.image_feature_source.index+1}_{ self.image_feature_destination.index+1}.jpg\"),self.img_with_match)\n",
    "    \n",
    "    #This function allows to check whether the match between the source and destination images is to be considered a good match\n",
    "    def check_salient(self, threshold, save_output = False, output_dir = \"output\"):\n",
    "        #A threshold is used to define the goodness of the  match\n",
    "        if len(self.good) > threshold:\n",
    "            if save_output:\n",
    "                cv.imwrite(os.path.join(output_dir,f\"salient_{self.image_feature_source.index+1}_{ self.image_feature_destination.index+1}.jpg\"),self.img_with_match)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def mult_and_norm(self,H, points):\n",
    "        proj_p = np.dot(H,points)\n",
    "        proj_p = proj_p / proj_p[2,:]\n",
    "        return proj_p[0:2,:]\n",
    "    \n",
    "    #This function allows to estimate the homography between the two images\n",
    "    def fit_homography(self, RANSACmaxIters = 2000, T_norm = np.eye(3)):\n",
    "        self.src_pts = np.float32([self.image_feature_source.kp[m[0].queryIdx].pt for m in self.good])\n",
    "        self.dst_pts = np.float32([self.image_feature_destination.kp[m[0].trainIdx].pt for m in self.good])\n",
    "        \n",
    "        self.src_pts = np.concatenate((self.src_pts, np.ones([self.src_pts.shape[0],1])), axis=1)\n",
    "        self.dst_pts = np.concatenate((self.dst_pts, np.ones([self.dst_pts.shape[0],1])), axis=1)\n",
    "        \n",
    "        \n",
    "        src_pts_proj = self.mult_and_norm(np.eye(3),self.src_pts.transpose()).transpose()\n",
    "        dst_pts_proj = self.mult_and_norm(np.eye(3),self.dst_pts.transpose()).transpose()\n",
    "        \n",
    "        \n",
    "        self.M, self.mask = cv.findHomography(src_pts_proj, dst_pts_proj, cv.RANSAC, 3.0, maxIters=RANSACmaxIters)\n",
    "        self.M = T_norm @ self.M @ np.linalg.inv(T_norm)\n",
    "    \n",
    "    #This function allows to normalize the homography so that the determinant is unitary\n",
    "    #This makes homographies part of the SL(3) group\n",
    "    def normalize_homography(self):\n",
    "        det = np.linalg.det(self.M)\n",
    "        self.H = self.M/np.cbrt(det)\n",
    "        new_det = np.linalg.det(self.H)\n",
    "        \n",
    "    #Remember: if src is image I and dest is image J, we are finding H from I to J, this is \n",
    "    #Hj,i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "47b0e6bb-1c10-4048-a1e6-50a1f12fc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matches(imgs,\n",
    "                    T_norm,\n",
    "                   save_images = False,\n",
    "                   matching_threshold = 0.6,\n",
    "                   matches_dir = \"matches\",\n",
    "                   matches_th = 20,\n",
    "                   number_of_matches=1,\n",
    "                   salient_matches_dir = \"salient_matches\",\n",
    "                   sift_dir = \"sift\",\n",
    "                   RANSACmaxIters = 2000):\n",
    "    n = len(imgs)\n",
    "    image_features =[] #Array that will contain the salient features of each image\n",
    "    for i in range(0,n):\n",
    "        image_feature = ImageFeature(imgs[i], i)\n",
    "        image_feature.SIFT(save_images, sift_dir)\n",
    "        image_features.append(image_feature)\n",
    "        \n",
    "    #Compute the good matches between each pair of images\n",
    "    matches =[]\n",
    "    for i in range(0, n-1):\n",
    "        for j in range(i+1, n):\n",
    "            for k in range(0,number_of_matches):\n",
    "                match = Match(image_features[i], image_features[j])\n",
    "                match.feature_matching(matching_threshold, save_images, matches_dir)\n",
    "                matches.append(match)\n",
    "\n",
    "\n",
    "    salient_matches = list(filter(lambda x: x.check_salient(matches_th, save_images, salient_matches_dir),matches))\n",
    "    \n",
    "    #For every good match, compute also the matches in the reverse order (destination, source) and compute homographies\n",
    "    total_matches = []\n",
    "    for match in salient_matches:\n",
    "        inv_match = Match(match.image_feature_destination, match.image_feature_source)\n",
    "        inv_match.feature_matching(matching_threshold, save_images, matches_dir)\n",
    "        match.fit_homography(RANSACmaxIters, T_norm)\n",
    "        match.normalize_homography()\n",
    "        inv_match.fit_homography(RANSACmaxIters, T_norm)\n",
    "        inv_match.normalize_homography()\n",
    "        total_matches.append(match)\n",
    "        total_matches.append(inv_match)\n",
    "        \n",
    "    return total_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "250c38a0-00d1-4c96-8c39-667a9240356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_graph(adj_matrix):\n",
    "    replicas_structure = dict()\n",
    "    adj_matrix_exp = np.copy(adj_matrix)\n",
    "    \n",
    "    #more multiedges, we have to expand\n",
    "    while np.sum(adj_matrix_exp>1)>0:\n",
    "        \n",
    "        adj_matrix_multi = np.maximum(adj_matrix_exp-1,0)\n",
    "        edges_out = np.sum(adj_matrix_multi, axis=1)\n",
    "        node_max = np.argmax(edges_out)\n",
    "        replicas = np.max(adj_matrix_multi[node_max,:])\n",
    "        appended_column = np.copy(adj_matrix_exp[:,node_max])\n",
    "        appended_column[node_max]=1\n",
    "        for i in range(replicas):\n",
    "            adj_matrix_exp = np.c_[adj_matrix_exp,appended_column]\n",
    "\n",
    "        row=np.copy(adj_matrix_exp[node_max,:])\n",
    "\n",
    "        appended_row = np.minimum(1,row)\n",
    "        adj_matrix_exp[node_max,:] = appended_row\n",
    "        row = np.maximum(0,row-1)\n",
    "        for i in range(replicas):\n",
    "            appended_row = np.minimum(1,row)\n",
    "            adj_matrix_exp = np.r_[adj_matrix_exp, [appended_row]]\n",
    "            row = np.maximum(0,row-1)\n",
    "        \n",
    "        replicas_structure[node_max] = [node_max] +  list(range(adj_matrix_exp.shape[0]-replicas, adj_matrix_exp.shape[0]))\n",
    "        \n",
    "    return adj_matrix_exp, replicas_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "039a43b1-5e2b-463e-9665-945c565cdcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Z_matrix(n, replicas, matches):\n",
    "\n",
    "    matches_handled = np.zeros([n,n], dtype=int)\n",
    "    Z = np.eye(3*n, 3*n)\n",
    "    for match in matches:\n",
    "        \n",
    "        i_temp=match.image_feature_source.index\n",
    "        j=match.image_feature_destination.index\n",
    "        if i_temp in replicas:\n",
    "            i = replicas[i_temp][(matches_handled[i_temp,j])]\n",
    "        else:\n",
    "            i=i_temp    \n",
    "        if j in replicas:\n",
    "            for k in replicas[j]:\n",
    "                Z[3*k:3*(k+1),3*i:3*(i+1)] = match.H\n",
    "        else:\n",
    "            Z[3*j:3*(j+1),3*i:3*(i+1)] = match.H\n",
    "        matches_handled[i_temp,j]+=1\n",
    "\n",
    "    for replica in replicas:\n",
    "        r = replicas[replica]\n",
    "        for k in r:\n",
    "            #add identity constraint (replica -> original node)\n",
    "            Z[3*k:3*(k+1),3*r[0]:3*(r[0]+1)] = np.eye(3)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "08f2c0bf-4569-4c45-9afe-31f84bd74913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_C_matrix(n_expanded, n, replicas):\n",
    "    C = np.zeros([3*n_expanded, 3*(n_expanded-n)],dtype=int)\n",
    "    for replica in replicas:\n",
    "        r = replicas[replica]\n",
    "        first = r[0]\n",
    "        for k in r:\n",
    "            if k != first:\n",
    "                C[3*first:3*(first+1),3*(k-n):3*(k-n+1)] = np.eye(3)\n",
    "                C[3*k:3*(k+1),3*(k-n):3*(k-n+1)] = -np.eye(3)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "205f93f3-cd24-446d-ab6e-013da495fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_M_matrix(adj_matrix, n, Z):\n",
    "    D = np.diag(np.sum(adj_matrix + np.eye(n), axis=1))\n",
    "    D_kron = np.kron(D, np.eye(3))\n",
    "    M = Z - D_kron\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6b71fde8-432f-41b9-bdc5-26a1d5639b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_matrices(dataset_name,\n",
    "                imgs,\n",
    "                T_norm,\n",
    "                matching_threshold = 0.6,\n",
    "                number_of_matches = 1,\n",
    "                matches_th = 20,\n",
    "                RANSACmaxIters = 2000,\n",
    "                save_output = True,\n",
    "                save_images = True,\n",
    "                output_dir =\"output\",\n",
    "                results_dir = \"results\",\n",
    "                verbose = True\n",
    "               ):\n",
    "    \n",
    "        M_filename = f\"M_{dataset_name}.npy\"\n",
    "        C_filename = f\"C_{dataset_name}.npy\"\n",
    "        Z_filename = f\"Z_{dataset_name}.npy\"\n",
    "        Adj_filename = f\"Adj_{dataset_name}.npy\"\n",
    "        Weight_filename = f\"W_{dataset_name}.npy\"\n",
    "        \n",
    "        sift_dir = os.path.join(results_dir,'sift')\n",
    "        matches_dir = os.path.join(results_dir,'matches')\n",
    "        salient_matches_dir = os.path.join(results_dir,'salient_matches')\n",
    "        graph_dir = os.path.join(results_dir,'graph')\n",
    "        \n",
    "        if save_images:\n",
    "            shutil.rmtree(results_dir)\n",
    "            if not os.path.isdir(results_dir):   \n",
    "                os.mkdir(results_dir)\n",
    "            if not os.path.isdir(sift_dir):\n",
    "                os.mkdir(sift_dir)\n",
    "            if not os.path.isdir(matches_dir):\n",
    "                os.mkdir(matches_dir)\n",
    "            if not os.path.isdir(salient_matches_dir):\n",
    "                os.mkdir(salient_matches_dir)   \n",
    "            if not os.path.isdir(graph_dir):\n",
    "                os.mkdir(graph_dir)\n",
    "        \n",
    "        if save_output:\n",
    "            if not os.path.isdir(output_dir):\n",
    "                os.mkdir(output_dir)\n",
    "            \n",
    "        n = len(imgs)\n",
    "        \n",
    "        matches = compute_matches(imgs = imgs, \n",
    "                                  T_norm = T_norm,\n",
    "                                  save_images= save_images, \n",
    "                                  matching_threshold = matching_threshold, \n",
    "                                  matches_dir = matches_dir, \n",
    "                                  number_of_matches = number_of_matches,\n",
    "                                  salient_matches_dir = salient_matches_dir, \n",
    "                                  sift_dir = sift_dir,\n",
    "                                  RANSACmaxIters = RANSACmaxIters)\n",
    "        \n",
    "        #compute the adj and weight matrix of matches\n",
    "        weight_matrix = np.zeros([n,n])\n",
    "        adj_matrix = np.zeros([n,n], dtype=int)\n",
    "        for match in matches:\n",
    "            adj_matrix[match.image_feature_source.index, match.image_feature_destination.index]+=1\n",
    "            weight_matrix[match.image_feature_source.index, match.image_feature_destination.index]=len(match.good)\n",
    "            \n",
    "        adj_matrix_exp, replicas = expand_graph(adj_matrix)\n",
    "        \n",
    "        \n",
    "        if verbose:       \n",
    "            Utils.build_and_print_multi_graph(adj_matrix, save_images, graph_dir, \"graph\")       #not expanded\n",
    "            Utils.build_and_print_multi_graph(adj_matrix_exp, save_images, graph_dir, \"expanded_graph\")   #expanded\n",
    "        \n",
    "        n_expanded = adj_matrix_exp.shape[0]\n",
    "        Z = compute_Z_matrix(n_expanded, replicas, matches)\n",
    "        \n",
    "        C = compute_C_matrix(n_expanded, n, replicas)\n",
    "        \n",
    "        M = compute_M_matrix(adj_matrix_exp, n_expanded, Z)\n",
    "        \n",
    "        if save_output:\n",
    "            np.save(os.path.join(output_dir,M_filename), M)\n",
    "            np.save(os.path.join(output_dir,Z_filename), Z)\n",
    "            np.save(os.path.join(output_dir,C_filename), C)\n",
    "            np.save(os.path.join(output_dir,Adj_filename), adj_matrix_exp)\n",
    "            np.save(os.path.join(output_dir,Weight_filename), weight_matrix)\n",
    "        \n",
    "        if verbose:#pay attention\n",
    "            allDone()\n",
    "        \n",
    "        return M, Z, C, adj_matrix_exp, weight_matrix\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
