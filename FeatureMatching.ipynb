{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4fb63f-ce48-48db-9a5c-c5f6fc87d7b7",
   "metadata": {},
   "source": [
    "# Feature Matching\n",
    "This notebook contains the code to perform feature matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdc370-1527-46a1-9792-0a09921610e1",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8008b65-3e11-45e4-bdf8-0ca43d4514d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import networkx as nx\n",
    "from IPython.display import Audio, display\n",
    "import ipynb.fs.defs.Utils as Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb91681-5c51-46a4-9499-7ac6f0a8c1b7",
   "metadata": {},
   "source": [
    "## Classes definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cd8ad4-97bf-40d4-82d0-38d8c599cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class contains the methods and properties related to the features of an image\n",
    "class ImageFeature:\n",
    "    def __init__(self, image, index):\n",
    "        self.image = image\n",
    "        self.index = index  \n",
    "        \n",
    "    #Compute the salient points of the image using SIFT algorithm\n",
    "    def SIFT(self,\n",
    "             save_output = False, #If True saves the output\n",
    "             output_dir = \"output\", #Output directory\n",
    "             noise_type = None, #Type of noise to be used\n",
    "             noise_std = 0.0 #Noise standard deviation\n",
    "            ):\n",
    "        sift = cv.SIFT_create()\n",
    "        #Detect keypoints and their descriptors\n",
    "        self.kp, self.des = sift.detectAndCompute(self.image,None)\n",
    "        \n",
    "        #Add noise to the detected points if required\n",
    "        if noise_type == Utils.NoiseType.POINTS:\n",
    "            for i in range(len(self.kp)):\n",
    "                self.kp[i].pt += np.random.normal(scale = noise_std , size = (2,)) #Add Gaussian noise with the specified standard deviation\n",
    "        self.img_with_sift=cv.drawKeypoints(self.image,self.kp,np.copy(self.image))\n",
    "        #If required, save the intermediate results\n",
    "        if save_output:\n",
    "            cv.imwrite(os.path.join(output_dir,f\"{self.index+1}.jpg\"), cv.cvtColor(self.img_with_sift,cv.COLOR_RGB2BGR))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e5080f-42ad-4219-96e5-0abd02dc2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class contains the methods and properties related to the problem of feature matching between two images\n",
    "class Match:\n",
    "    def __init__(self,\n",
    "                 image_feature_source, #Source image\n",
    "                 image_feature_destination #Destination image\n",
    "                ):\n",
    "        self.image_feature_source = image_feature_source\n",
    "        self.image_feature_destination = image_feature_destination\n",
    "    \n",
    "    #This function performs feature matching between to images\n",
    "    def feature_matching(self, threshold, save_output = False, output_dir = \"output\"):\n",
    "        # FLANN parameters\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)\n",
    "        \n",
    "        #Detect matches using FLANN\n",
    "        flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "        \n",
    "        bf = cv.BFMatcher()\n",
    "        matches = bf.knnMatch(self.image_feature_source.des,\n",
    "                                 self.image_feature_destination.des,\n",
    "                                 k=2)\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        self.good = []\n",
    "        for m in matches:\n",
    "            if m[0].distance < threshold*m[1].distance:\n",
    "                self.good.append((m[0],m[0]))\n",
    "        draw_params = dict(matchColor = (0,255,0),\n",
    "                           singlePointColor = (255,0,0),\n",
    "                           flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "        self.img_with_match = cv.drawMatchesKnn(self.image_feature_source.image,\n",
    "                                                self.image_feature_source.kp,\n",
    "                                                self.image_feature_destination.image,\n",
    "                                                self.image_feature_destination.kp,\n",
    "                                                self.good,None,**draw_params)\n",
    "        \n",
    "        self.num_matches = len(self.good)\n",
    "        \n",
    "        #Compute source and destination points\n",
    "        self.src_pts = np.double([self.image_feature_source.kp[m[0].queryIdx].pt for m in self.good])\n",
    "        self.dst_pts = np.double([self.image_feature_destination.kp[m[0].trainIdx].pt for m in self.good])\n",
    "        \n",
    "        #Save the output if required\n",
    "        if save_output:\n",
    "            cv.imwrite(os.path.join(output_dir,f\"match_{self.image_feature_source.index+1}_{ self.image_feature_destination.index+1}.jpg\"),cv.cvtColor(self.img_with_match,cv.COLOR_RGB2BGR))\n",
    "    \n",
    "    #This function allows to check whether the match between the source and destination images is to be considered a good match\n",
    "    def check_salient(self, threshold, save_output = False, output_dir = \"output\"):\n",
    "        #A threshold is used to define the goodness of the  match\n",
    "        if self.num_matches > threshold:\n",
    "            if save_output:\n",
    "                cv.imwrite(os.path.join(output_dir,f\"salient_{self.image_feature_source.index+1}_{ self.image_feature_destination.index+1}.jpg\"),cv.cvtColor(self.img_with_match,cv.COLOR_RGB2BGR))\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    #This function allows to compute and normalize the projected points\n",
    "    def mult_and_norm(self,H, points):\n",
    "        proj_p = np.dot(H,points)\n",
    "        proj_p = proj_p / proj_p[2,:]\n",
    "        return proj_p[0:2,:]\n",
    "    \n",
    "    #This function allows to estimate the homography between the two images\n",
    "    def fit_homography(self,\n",
    "                       RANSACmaxIters = 2000, #Number of iterations of RANSAC\n",
    "                       T_norm = np.eye(3), #Normalization matrix\n",
    "                       noise_type = Utils.NoiseType.NO_NOISE, #Type of noise to be used\n",
    "                       noise_std = 0.1  #Standare deviation of the Gaussian noise\n",
    "                      ):\n",
    "        \n",
    "        #Move points to the homogeneous space\n",
    "        self.src_pts = np.concatenate((self.src_pts, np.ones([self.src_pts.shape[0],1])), axis=1)\n",
    "        self.dst_pts = np.concatenate((self.dst_pts, np.ones([self.dst_pts.shape[0],1])), axis=1)\n",
    "        \n",
    "        src_pts_proj = self.mult_and_norm(T_norm,self.src_pts.transpose()).transpose() #Compute normalized source points\n",
    "        dst_pts_proj = self.mult_and_norm(T_norm,self.dst_pts.transpose()).transpose() #Compute normalized destination points\n",
    "        \n",
    "        #Compute the homography from source image to destination image\n",
    "        self.M, _ = cv.findHomography(src_pts_proj, dst_pts_proj, cv.RANSAC, 3*T_norm[0][0], 3.0, maxIters=RANSACmaxIters )\n",
    "\n",
    "        #If required add some noise to the estimated homography\n",
    "        if noise_type == Utils.NoiseType.HOMOGRAPHY:\n",
    "            self.M += np.random.normal(scale = noise_std , size = [3,3]) #Add some random noise to the homography\n",
    "    \n",
    "    #This function allows to normalize the homography so that the determinant is unitary\n",
    "    #This makes homographies part of the SL(3) group\n",
    "    def normalize_homography(self):\n",
    "        det = np.linalg.det(self.M)\n",
    "        self.H = self.M/np.cbrt(det)\n",
    "        new_det = np.linalg.det(self.H)\n",
    "    \n",
    "    #This function allows to define a copy of the match\n",
    "    def copy(self):\n",
    "        copy = Match(self.image_feature_source,\n",
    "                    self.image_feature_destination )\n",
    "        copy.img_with_match = self.img_with_match\n",
    "        copy.good = self.good\n",
    "        copy.num_matches = self.num_matches\n",
    "        copy.src_pts = np.copy(self.src_pts)\n",
    "        copy.dst_pts = np.copy(self.dst_pts)\n",
    "        return copy\n",
    "    \n",
    "    #This function allows to compute the inverse match (from destination to source)\n",
    "    def get_inv_match(self):\n",
    "        inv_match = Match(self.image_feature_destination, self.image_feature_source)\n",
    "        inv_match.num_matches = self.num_matches\n",
    "        inv_match.dst_pts = np.copy(self.src_pts) #The new destination points are the source ones\n",
    "        inv_match.src_pts = np.copy(self.dst_pts) #The new source points are the destination ones\n",
    "        return inv_match\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5acca68-7f04-4a3b-91fb-c7f048241c15",
   "metadata": {},
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f820bee-93c2-408b-95ef-a0d81fe90276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used the alert that the procedure is finished\n",
    "def allDone():\n",
    "    print(\" --- finished --- \")\n",
    "    #display(Audio(url='https://sound.peal.io/ps/audios/000/001/131/original/kon.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947399c9-7e0f-4d47-8fba-d0f2bb2dc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function allows to compute matches between two images\n",
    "def compute_matches(imgs, #Images for which matches should be computed\n",
    "                    T_norm, #Normalization matrix\n",
    "                    save_images = False, #If True saves the intermediate results\n",
    "                    matching_threshold = 0.6, #Threshold used to compute matches\n",
    "                    matches_dir = \"matches\", #Directory where to save matches\n",
    "                    matches_th = 20, #Threshold used to compute good matches\n",
    "                    number_of_matches=1, #Number of times the matching procedure should be repeated (multi-edge degree)\n",
    "                    noise_std = 0.1, #Standard deviation of the gaussian noise\n",
    "                    salient_matches_dir = \"salient_matches\", #Directory where to save good matches\n",
    "                    sift_dir = \"sift\", #Directory where to save SIFT results\n",
    "                    RANSACmaxIters = 2000, #Number of RANSAC iterations\n",
    "                    noise_type = Utils.NoiseType.NO_NOISE\n",
    "                   ):\n",
    "    n = len(imgs)\n",
    "    image_features =[] #Array that will contain the salient features of each image\n",
    "    \n",
    "    #Compute salient points of each image using SIFT\n",
    "    for i in range(0,n):\n",
    "        for k in range(0,number_of_matches):\n",
    "            image_feature = ImageFeature(imgs[i], i)\n",
    "            image_feature.SIFT(save_images, sift_dir, noise_type = noise_type, noise_std = noise_std)\n",
    "            if len(image_features) <= i:\n",
    "                image_features.append([image_feature])\n",
    "            else:\n",
    "                image_features[i].append(image_feature)\n",
    "                \n",
    "    #Compute the good matches between each pair of images\n",
    "    matches =[]\n",
    "    for k in range(0,number_of_matches):\n",
    "        for i in range(0, n-1):\n",
    "            for j in range(i+1, n):\n",
    "                match = Match(image_features[i][k], image_features[j][k])\n",
    "                match.feature_matching(matching_threshold, save_images, matches_dir)            \n",
    "                matches.append(match)\n",
    "    \n",
    "    salient_matches = list(filter(lambda x: x.check_salient(matches_th, save_images, salient_matches_dir),matches))\n",
    "    \n",
    "    #For every good match, compute also the matches in the reverse order (destination, source) and compute homographies\n",
    "    total_matches = []\n",
    "    for match in salient_matches:\n",
    "        inv_match = match.get_inv_match()\n",
    "        \n",
    "        match.fit_homography(RANSACmaxIters, T_norm, noise_type = noise_type, noise_std = noise_std)\n",
    "        match.normalize_homography()\n",
    "        total_matches.append(match)\n",
    "        \n",
    "        inv_match.fit_homography(RANSACmaxIters, T_norm, noise_type = noise_type, noise_std = noise_std)\n",
    "        inv_match.normalize_homography()\n",
    "        total_matches.append(inv_match)\n",
    "    return total_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42c116e-6115-4b08-8995-807866883be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function allows to perform the whole feature matching procedure\n",
    "def get_feature_matches(dataset_name, #Name of the dataset to be used\n",
    "                imgs, #Images used to compute matches\n",
    "                T_norm, #Normalization matrix\n",
    "                matching_threshold = 0.6, #Threshold used to compute matches\n",
    "                number_of_matches = 1, #Number of times the matching procedure should be repeated (multi-edge degree)\n",
    "                noise_std = 0.1, #Standard deviation of the Gaussian noise\n",
    "                matches_th = 20, #Threshold used to compute good matches\n",
    "                RANSACmaxIters = 2000, #Number of RANSAC iterations\n",
    "                save_images = True, #If True saves intermediate results\n",
    "                save_output = True, #If True saves output\n",
    "                output_dir =\"output\", #Output directory\n",
    "                results_dir = \"results\", #Intermediate results directory\n",
    "                noise_type = Utils.NoiseType.NO_NOISE, #Type of noise to be used\n",
    "                verbose = True #If True signal when the procedure is concluded\n",
    "               ):\n",
    "        \n",
    "        #Define directories\n",
    "        sift_dir = os.path.join(results_dir,'sift')\n",
    "        matches_dir = os.path.join(results_dir,'matches')\n",
    "        salient_matches_dir = os.path.join(results_dir,'salient_matches')\n",
    "        Weight_filename = f\"W_{dataset_name}.npy\"\n",
    "        \n",
    "        #Create directories if not exist\n",
    "        if save_images:\n",
    "            shutil.rmtree(results_dir, ignore_errors = True)\n",
    "            if not os.path.isdir(results_dir):   \n",
    "                os.mkdir(results_dir)\n",
    "            if not os.path.isdir(sift_dir):\n",
    "                os.mkdir(sift_dir)\n",
    "            if not os.path.isdir(matches_dir):\n",
    "                os.mkdir(matches_dir)\n",
    "            if not os.path.isdir(salient_matches_dir):\n",
    "                os.mkdir(salient_matches_dir)   \n",
    "            \n",
    "        n = len(imgs)\n",
    "\n",
    "        #Compute matches\n",
    "        matches = compute_matches(imgs = imgs, \n",
    "                                  T_norm = T_norm,\n",
    "                                  save_images= save_images, \n",
    "                                  matching_threshold = matching_threshold, \n",
    "                                  matches_dir = matches_dir, \n",
    "                                  matches_th = matches_th,\n",
    "                                  number_of_matches = number_of_matches,\n",
    "                                  noise_std = noise_std,\n",
    "                                  salient_matches_dir = salient_matches_dir, \n",
    "                                  sift_dir = sift_dir,\n",
    "                                  RANSACmaxIters = RANSACmaxIters,\n",
    "                                  noise_type = noise_type\n",
    "                                 )\n",
    "        \n",
    "        #Create matches dictionary and weight matrix\n",
    "        matches_dict = dict()\n",
    "        weight_matrix = np.zeros([n,n])\n",
    "        for match in matches:\n",
    "            i,j = match.image_feature_source.index, match.image_feature_destination.index\n",
    "            if (i, j) not in matches_dict:\n",
    "                matches_dict[i, j] = list()\n",
    "            matches_dict[i, j].append(match.H)\n",
    "            weight_matrix[i, j] = match.num_matches\n",
    "        \n",
    "        #If required save output\n",
    "        if save_output:\n",
    "            if not os.path.isdir(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            np.save(os.path.join(output_dir,Weight_filename), weight_matrix)\n",
    "\n",
    "        #If required signal when the procedure is finished\n",
    "        if verbose:\n",
    "            allDone()\n",
    "        \n",
    "        return matches_dict, weight_matrix\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
