{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af4778a-c650-445c-8464-5401488b2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import networkx as nx\n",
    "from IPython.display import Audio, display\n",
    "import ipynb.fs.defs.Utils as Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5365d9e3-37ec-440f-a955-b840c05a1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allDone():\n",
    "    print(\" --- finished --- \")\n",
    "    #display(Audio(url='https://sound.peal.io/ps/audios/000/001/131/original/kon.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d78987-9a8a-4dbe-ab83-1566030debd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class contains the methods and properties related to the features of an image\n",
    "class ImageFeature:\n",
    "    def __init__(self, image, index):\n",
    "        self.image = image\n",
    "        self.index = index  \n",
    "        \n",
    "    #Compute the salient points of the image using SIFT algorithm\n",
    "    def SIFT(self, save_output = False, output_dir = \"output\"):\n",
    "        sift = cv.SIFT_create()\n",
    "        self.kp, self.des = sift.detectAndCompute(self.image,None)\n",
    "        self.img_with_sift=cv.drawKeypoints(self.image,self.kp,np.copy(self.image))\n",
    "        if save_output:\n",
    "            cv.imwrite(os.path.join(output_dir,f\"{self.index+1}.jpg\"), self.img_with_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e1ce70-ef10-43c4-a83b-a6d8710f9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class contains the methods and properties related to the problem of feature matching between two images\n",
    "class Match:\n",
    "    def __init__(self, image_feature_source, image_feature_destination):\n",
    "        self.image_feature_source = image_feature_source\n",
    "        self.image_feature_destination = image_feature_destination\n",
    "    \n",
    "    #This function performs feature matching between to images\n",
    "    def feature_matching(self, threshold, save_output = False, output_dir = \"output\", noisy = False):\n",
    "        # FLANN parameters\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "        flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "        \n",
    "        bf = cv.BFMatcher()\n",
    "        matches = bf.knnMatch(self.image_feature_source.des,\n",
    "                                 self.image_feature_destination.des,\n",
    "                                 k=3)\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        self.good = []\n",
    "        for m in matches:\n",
    "            if m[0].distance < threshold*m[1].distance:\n",
    "                r_m = np.random.choice(m) if noisy else m[0]\n",
    "                self.good.append((r_m,r_m))\n",
    "        draw_params = dict(matchColor = (0,255,0),\n",
    "                           singlePointColor = (255,0,0),\n",
    "                           flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "        self.img_with_match = cv.drawMatchesKnn(self.image_feature_source.image,\n",
    "                                                self.image_feature_source.kp,\n",
    "                                                self.image_feature_destination.image,\n",
    "                                                self.image_feature_destination.kp,\n",
    "                                                self.good,None,**draw_params)\n",
    "        if save_output:\n",
    "            cv.imwrite(os.path.join(output_dir,f\"match_{self.image_feature_source.index+1}_{ self.image_feature_destination.index+1}.jpg\"),self.img_with_match)\n",
    "    \n",
    "    #This function allows to check whether the match between the source and destination images is to be considered a good match\n",
    "    def check_salient(self, threshold, save_output = False, output_dir = \"output\"):\n",
    "        #A threshold is used to define the goodness of the  match\n",
    "        if len(self.good) > threshold:\n",
    "            if save_output:\n",
    "                cv.imwrite(os.path.join(output_dir,f\"salient_{self.image_feature_source.index+1}_{ self.image_feature_destination.index+1}.jpg\"),self.img_with_match)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def mult_and_norm(self,H, points):\n",
    "        proj_p = np.dot(H,points)\n",
    "        proj_p = proj_p / proj_p[2,:]\n",
    "        return proj_p[0:2,:]\n",
    "    \n",
    "    #This function allows to estimate the homography between the two images\n",
    "    def fit_homography(self, RANSACmaxIters = 2000, T_norm = np.eye(3)):\n",
    "        self.src_pts = np.double([self.image_feature_source.kp[m[0].queryIdx].pt for m in self.good])\n",
    "        self.dst_pts = np.double([self.image_feature_destination.kp[m[0].trainIdx].pt for m in self.good])\n",
    "        \n",
    "        self.src_pts = np.concatenate((self.src_pts, np.ones([self.src_pts.shape[0],1])), axis=1)\n",
    "        self.dst_pts = np.concatenate((self.dst_pts, np.ones([self.dst_pts.shape[0],1])), axis=1)\n",
    "        \n",
    "        \n",
    "        src_pts_proj = self.mult_and_norm(T_norm,self.src_pts.transpose()).transpose()\n",
    "        dst_pts_proj = self.mult_and_norm(T_norm,self.dst_pts.transpose()).transpose()\n",
    "        \n",
    "        \n",
    "        self.M, self.mask = cv.findHomography(src_pts_proj, dst_pts_proj, cv.RANSAC, 3*T_norm[0][0], 3.0, maxIters=RANSACmaxIters )\n",
    "    \n",
    "    #This function allows to normalize the homography so that the determinant is unitary\n",
    "    #This makes homographies part of the SL(3) group\n",
    "    def normalize_homography(self):\n",
    "        det = np.linalg.det(self.M)\n",
    "        self.H = self.M/np.cbrt(det)\n",
    "        new_det = np.linalg.det(self.H)\n",
    "        \n",
    "    #Remember: if src is image I and dest is image J, we are finding H from I to J, this is \n",
    "    #Hj,i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b0e6bb-1c10-4048-a1e6-50a1f12fc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matches(imgs,\n",
    "                    T_norm,\n",
    "                    save_images = False,\n",
    "                    matching_threshold = 0.6,\n",
    "                    matches_dir = \"matches\",\n",
    "                    matches_th = 20,\n",
    "                    number_of_matches=1,\n",
    "                    salient_matches_dir = \"salient_matches\",\n",
    "                    sift_dir = \"sift\",\n",
    "                    RANSACmaxIters = 2000,\n",
    "                    noisy_matching = False):\n",
    "    n = len(imgs)\n",
    "    image_features =[] #Array that will contain the salient features of each image\n",
    "    for i in range(0,n):\n",
    "        image_feature = ImageFeature(imgs[i], i)\n",
    "        image_feature.SIFT(save_images, sift_dir)\n",
    "        image_features.append(image_feature)\n",
    "        \n",
    "    #Compute the good matches between each pair of images\n",
    "    matches =[]\n",
    "    for i in range(0, n-1):\n",
    "        for j in range(i+1, n):\n",
    "            for k in range(0,number_of_matches):\n",
    "                match = Match(image_features[i], image_features[j])\n",
    "                match.feature_matching(matching_threshold, save_images, matches_dir, noisy = noisy_matching)\n",
    "                matches.append(match)\n",
    "\n",
    "\n",
    "    salient_matches = list(filter(lambda x: x.check_salient(matches_th, save_images, salient_matches_dir),matches))\n",
    "    \n",
    "    #For every good match, compute also the matches in the reverse order (destination, source) and compute homographies\n",
    "    total_matches = []\n",
    "    for match in salient_matches:\n",
    "        inv_match = Match(match.image_feature_destination, match.image_feature_source)\n",
    "        inv_match.feature_matching(matching_threshold, save_images, matches_dir, noisy = noisy_matching)\n",
    "        match.fit_homography(RANSACmaxIters, T_norm)\n",
    "        match.normalize_homography()\n",
    "        inv_match.fit_homography(RANSACmaxIters, T_norm)\n",
    "        inv_match.normalize_homography()\n",
    "        total_matches.append(match)\n",
    "        total_matches.append(inv_match)\n",
    "        \n",
    "    return total_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b71fde8-432f-41b9-bdc5-26a1d5639b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_matches(dataset_name,\n",
    "                imgs,\n",
    "                T_norm,\n",
    "                matching_threshold = 0.6,\n",
    "                number_of_matches = 1,\n",
    "                matches_th = 20,\n",
    "                RANSACmaxIters = 2000,\n",
    "                save_images = True,\n",
    "                save_output = True,\n",
    "                output_dir =\"output\",\n",
    "                results_dir = \"results\",\n",
    "                noisy_matching = False,\n",
    "                verbose = True\n",
    "               ):\n",
    "        \n",
    "        sift_dir = os.path.join(results_dir,'sift')\n",
    "        matches_dir = os.path.join(results_dir,'matches')\n",
    "        salient_matches_dir = os.path.join(results_dir,'salient_matches')\n",
    "        Weight_filename = f\"W_{dataset_name}.npy\"\n",
    "        \n",
    "        if save_images:\n",
    "            shutil.rmtree(results_dir)\n",
    "            if not os.path.isdir(results_dir):   \n",
    "                os.mkdir(results_dir)\n",
    "            if not os.path.isdir(sift_dir):\n",
    "                os.mkdir(sift_dir)\n",
    "            if not os.path.isdir(matches_dir):\n",
    "                os.mkdir(matches_dir)\n",
    "            if not os.path.isdir(salient_matches_dir):\n",
    "                os.mkdir(salient_matches_dir)   \n",
    "            \n",
    "        n = len(imgs)\n",
    "        \n",
    "        matches = compute_matches(imgs = imgs, \n",
    "                                  T_norm = T_norm,\n",
    "                                  save_images= save_images, \n",
    "                                  matching_threshold = matching_threshold, \n",
    "                                  matches_dir = matches_dir, \n",
    "                                  matches_th = matches_th,\n",
    "                                  number_of_matches = number_of_matches,\n",
    "                                  salient_matches_dir = salient_matches_dir, \n",
    "                                  sift_dir = sift_dir,\n",
    "                                  RANSACmaxIters = RANSACmaxIters,\n",
    "                                  noisy_matching = noisy_matching\n",
    "                                 )\n",
    "        \n",
    "        matches_dict = dict()\n",
    "        weight_matrix = np.zeros([n,n])\n",
    "        for match in matches:\n",
    "            i,j = match.image_feature_source.index, match.image_feature_destination.index\n",
    "            if (i, j) not in matches_dict:\n",
    "                matches_dict[i, j] = list()\n",
    "            matches_dict[i, j].append(match.H)\n",
    "            weight_matrix[i, j] = len(match.good)\n",
    "        \n",
    "        if save_output:\n",
    "            if not os.path.isdir(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            np.save(os.path.join(output_dir,Weight_filename), weight_matrix)\n",
    "\n",
    "        if verbose:#pay attention\n",
    "            allDone()\n",
    "        \n",
    "        return matches_dict, weight_matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a506004-0aa5-45a1-bff9-c946180774e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
